"""
Pokeråœºæ™¯ä¸“ç”¨è¯„ä¼°è„šæœ¬
è¯„ä¼°æŒ‡æ ‡ï¼š
1. Hidden State Prediction - å¯¹æ‰‹èŒƒå›´/ç­–ç•¥æ¨æ–­å‡†ç¡®ç‡
2. Win Rate Improvement - æœ‰æ— memoryçš„èƒœç‡æå‡
3. Behavior Consistency - é•¿æœŸå¯¹æŠ—ä¸­çš„ä¸€è‡´æ€§
"""
import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import numpy as np
from typing import Dict, List, Any
from datetime import datetime
import json

# å°è¯•å¯¼å…¥Pokerç›¸å…³æ¨¡å—
try:
    from memory import PokerRLAgent, GameState, HandAction
except ImportError:
    try:
        # Fallback: try direct import
        from memory.poker_agent import PokerRLAgent
        from memory.best_response import GameState
        from memory.opponent_memory import HandAction
    except Exception as e:
        print(f"Warning: Could not import Poker modules: {e}")
        PokerRLAgent = None
        GameState = None
        HandAction = None
from evaluation.comparison.scenario_comparison import ScenarioComparison, create_baseline_agents


class PokerEvaluator:
    """Pokeråœºæ™¯è¯„ä¼°å™¨"""
    
    def __init__(self):
        self.results = {}
    
    def evaluate_hidden_state_prediction(self, agent, ground_truth: Dict) -> float:
        """
        è¯„ä¼°1: Hidden State Prediction (å¯¹æ‰‹èŒƒå›´/ç­–ç•¥æ¨æ–­å‡†ç¡®ç‡)
        """
        if not PokerRLAgent or not isinstance(agent, PokerRLAgent):
            return 0.0
        
        if not hasattr(agent, 'opponent_models') or not agent.opponent_models:
            return 0.0
        
        accuracies = []
        
        for opp_id, true_stats in ground_truth.items():
            if opp_id not in agent.opponent_models:
                continue
            
            model = agent.opponent_models[opp_id]
            
            # 1. Range prediction accuracy
            if 'true_range' in true_stats:
                true_range = true_stats['true_range']
                if hasattr(agent, 'range_estimators') and opp_id in agent.range_estimators:
                    pred_range = agent.range_estimators[opp_id].get_range()
                    if pred_range:
                        # L1 distance
                        range_error = sum(abs(pred_range.get(k, 0) - true_range.get(k, 0)) 
                                        for k in ['premium', 'strong', 'medium', 'weak', 'bluff'])
                        range_accuracy = max(0, 1.0 - range_error / 2.0)
                        accuracies.append(range_accuracy)
            
            # 2. VPIP/PFR accuracy
            if 'true_vpip' in true_stats:
                try:
                    tendency = model.get_tendency()
                    if tendency:
                        pred_vpip = tendency.vpip
                        vpip_error = abs(pred_vpip - true_stats['true_vpip'])
                        vpip_accuracy = max(0, 1.0 - vpip_error / 0.5)
                        accuracies.append(vpip_accuracy)
                except (AttributeError, TypeError):
                    pass
            
            if 'true_pfr' in true_stats:
                try:
                    tendency = model.get_tendency()
                    if tendency:
                        pred_pfr = tendency.pfr
                        pfr_error = abs(pred_pfr - true_stats['true_pfr'])
                        pfr_accuracy = max(0, 1.0 - pfr_error / 0.5)
                        accuracies.append(pfr_accuracy)
                except (AttributeError, TypeError):
                    pass
            
            # 3. Player type accuracy
            if 'true_player_type' in true_stats:
                pred_type = getattr(model, 'player_type', 'Unknown')
                type_accuracy = 1.0 if pred_type == true_stats['true_player_type'] else 0.0
                accuracies.append(type_accuracy)
        
        return np.mean(accuracies) if accuracies else 0.0
    
    def evaluate_win_rate_improvement(self, agent_with_memory, agent_without_memory=None) -> float:
        """
        è¯„ä¼°2: Win Rate Improvement (æœ‰æ— memoryçš„èƒœç‡æå‡)
        """
        if not hasattr(agent_with_memory, 'get_performance_metrics'):
            return 0.0
        
        metrics_with = agent_with_memory.get_performance_metrics()
        win_rate_with = metrics_with.get('win_rate', 0.5)
        
        if agent_without_memory:
            metrics_without = agent_without_memory.get_performance_metrics()
            win_rate_without = metrics_without.get('win_rate', 0.5)
        else:
            # å‡è®¾baselineæ˜¯50%èƒœç‡
            win_rate_without = 0.5
        
        improvement = win_rate_with - win_rate_without
        return improvement
    
    def evaluate_behavior_consistency(self, agent, test_episodes: List) -> float:
        """
        è¯„ä¼°3: Behavior Consistency (é•¿æœŸå¯¹æŠ—ä¸­çš„ä¸€è‡´æ€§)
        """
        if not test_episodes:
            return 0.5
        
        consistency_scores = []
        
        # åˆ†æå¤šä¸ªepisodeä¸­çš„å†³ç­–ä¸€è‡´æ€§
        decisions = []
        for episode in test_episodes:
            if 'decision' in episode:
                decisions.append(episode['decision'])
        
        if len(decisions) >= 2:
            # è®¡ç®—å†³ç­–çš„ç¨³å®šæ€§
            decision_variance = np.var([hash(str(d)) for d in decisions])
            consistency = 1.0 / (1.0 + decision_variance / 10.0)
            consistency_scores.append(consistency)
        
        # æ£€æŸ¥å¯¹æ‰‹é£æ ¼åˆ‡æ¢æ—¶çš„å“åº”é€Ÿåº¦
        if hasattr(agent, 'opponent_models'):
            for opp_id, model in agent.opponent_models.items():
                stats = model.get_model_summary()
                num_hands = stats.get('num_hands_observed', 0)
                if num_hands > 0:
                    # æ›´å¤šæ‰‹æ•° = æ›´å¥½çš„é•¿æœŸå»ºæ¨¡
                    consistency_scores.append(min(1.0, num_hands / 50.0))
        
        return np.mean(consistency_scores) if consistency_scores else 0.5
    
    def comprehensive_evaluation(self, agent, ground_truth: Dict, 
                               agent_without_memory=None,
                               test_episodes: List = None) -> Dict[str, Any]:
        """
        ç»¼åˆè¯„ä¼°Pokeråœºæ™¯
        """
        print("="*80)
        print("POKERåœºæ™¯è¯„ä¼°")
        print("="*80)
        
        # è¯„ä¼°ä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡
        metric1 = self.evaluate_hidden_state_prediction(agent, ground_truth)
        metric2 = self.evaluate_win_rate_improvement(agent, agent_without_memory)
        metric3 = self.evaluate_behavior_consistency(agent, test_episodes or [])
        
        # æ”¶é›†memoryç»Ÿè®¡
        memory_stats = {}
        if hasattr(agent, 'get_system_statistics'):
            memory_stats = agent.get_system_statistics().get('memory', {})
        
        # ç»¼åˆå¾—åˆ†
        overall_score = (metric1 + max(0, min(1, metric2 + 0.5)) + metric3) / 3.0
        
        results = {
            'scenario': 'poker',
            'evaluation_timestamp': datetime.now().isoformat(),
            'metrics': {
                'hidden_state_prediction_accuracy': float(metric1),
                'win_rate_improvement': float(metric2),
                'behavior_consistency': float(metric3)
            },
            'overall_score': float(overall_score),
            'memory_stats': memory_stats,
            'interpretation': {
                'hidden_state_prediction': 'ä¼˜ç§€' if metric1 > 0.8 else 'è‰¯å¥½' if metric1 > 0.6 else 'éœ€æ”¹è¿›',
                'win_rate_improvement': 'ä¼˜ç§€' if metric2 > 0.1 else 'è‰¯å¥½' if metric2 > 0.05 else 'éœ€æ”¹è¿›',
                'behavior_consistency': 'ä¼˜ç§€' if metric3 > 0.7 else 'è‰¯å¥½' if metric3 > 0.5 else 'éœ€æ”¹è¿›'
            }
        }
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
        print(f"   1. Hidden State Prediction: {metric1:.3f} ({results['interpretation']['hidden_state_prediction']})")
        print(f"   2. Win Rate Improvement: {metric2:+.3f} ({results['interpretation']['win_rate_improvement']})")
        print(f"   3. Behavior Consistency: {metric3:.3f} ({results['interpretation']['behavior_consistency']})")
        print(f"\n   ç»¼åˆå¾—åˆ†: {overall_score:.3f}")
        
        self.results = results
        return results
    
    def save_results(self, filepath: str):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)
        with open(filepath, 'w') as f:
            json.dump(self.results, f, indent=2, default=str)
        print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {filepath}")


def create_poker_ground_truth():
    """åˆ›å»ºPokerè¯„ä¼°çš„ground truthæ•°æ®"""
    return {
        "opponent_1": {
            "true_range": {
                "premium": 0.30,
                "strong": 0.35,
                "medium": 0.25,
                "weak": 0.05,
                "bluff": 0.05
            },
            "true_vpip": 0.25,
            "true_pfr": 0.15,
            "true_player_type": "TAG"
        },
        "opponent_2": {
            "true_range": {
                "premium": 0.10,
                "strong": 0.20,
                "medium": 0.30,
                "weak": 0.25,
                "bluff": 0.15
            },
            "true_vpip": 0.40,
            "true_pfr": 0.20,
            "true_player_type": "LAG"
        }
    }


def create_poker_test_episodes():
    """åˆ›å»ºPokeræµ‹è¯•episodes"""
    return [
        {
            "episode_id": "hand_001",
            "opponent_id": "opponent_1",
            "decision": "call",
            "context": "preflop_raise"
        },
        {
            "episode_id": "hand_002",
            "opponent_id": "opponent_1",
            "decision": "fold",
            "context": "river_bet"
        },
        {
            "episode_id": "hand_003",
            "opponent_id": "opponent_2",
            "decision": "raise",
            "context": "turn_bluff"
        }
    ]


def simulate_poker_hands(agent, ground_truth: Dict, num_hands_per_opponent: int = 20):
    """
    æ¨¡æ‹ŸPokeræ¸¸æˆæ‰‹æ•°ï¼Œè®©agentè®°å½•å¯¹æ‰‹åŠ¨ä½œ
    
    æ ¹æ®ground truthä¸­çš„å¯¹æ‰‹ç‰¹å¾ï¼Œæ¨¡æ‹Ÿä»–ä»¬çš„è¡Œä¸º
    """
    if not PokerRLAgent or not isinstance(agent, PokerRLAgent):
        return
    
    np.random.seed(42)  # å¯é‡å¤æ€§
    
    for opp_id, true_stats in ground_truth.items():
        # åˆå§‹åŒ–å¯¹æ‰‹
        agent.initialize_opponent(opp_id)
        
        # è·å–çœŸå®ç‰¹å¾
        true_vpip = true_stats.get('true_vpip', 0.25)
        true_pfr = true_stats.get('true_pfr', 0.15)
        true_player_type = true_stats.get('true_player_type', 'TAG')
        
        # æ¨¡æ‹Ÿå¤šæ‰‹æ¸¸æˆ
        for hand_num in range(num_hands_per_opponent):
            hand_id = f"{opp_id}_hand_{hand_num:03d}"
            
            # æ¨¡æ‹ŸpreflopåŠ¨ä½œ
            preflop_action_type = None
            if np.random.random() < true_vpip:
                # VPIP: ä¼šæŠ•å…¥èµ„é‡‘
                if np.random.random() < (true_pfr / true_vpip):
                    preflop_action_type = 'raise'
                else:
                    preflop_action_type = 'call'
            else:
                preflop_action_type = 'fold'
            
            # åˆ›å»ºpreflopåŠ¨ä½œ
            preflop_action = HandAction(
                action_type=preflop_action_type,
                amount=20.0 if preflop_action_type == 'raise' else (10.0 if preflop_action_type == 'call' else 0.0),
                street='preflop',
                position='middle',
                pot_size=30.0
            )
            agent.observe_action(opp_id, hand_id, preflop_action)
            
            # å¦‚æœæ²¡foldï¼Œæ¨¡æ‹Ÿåç»­è¡—é“
            if preflop_action_type != 'fold':
                # FlopåŠ¨ä½œ
                if np.random.random() < 0.6:  # 60% continuation bet
                    flop_action = HandAction(
                        action_type='bet',
                        amount=15.0,
                        street='flop',
                        position='middle',
                        pot_size=50.0
                    )
                    agent.observe_action(opp_id, hand_id, flop_action)
                
                # æ¨¡æ‹Ÿæ‰‹ç‰Œç»“æœï¼ˆå¶å°”showdownï¼‰
                if np.random.random() < 0.3:  # 30% showdown
                    final_action = 'showdown'
                    pot_outcome = np.random.choice([-20.0, 20.0])  # éšæœºè¾“èµ¢
                    
                    # æ ¹æ®player typeå†³å®šshowdown cards
                    if true_player_type == 'TAG':
                        # Tight-Aggressive: å¼ºç‰Œ
                        showdown_cards = ('As', 'Kh')
                    else:
                        # Loose: å¯èƒ½å¼±ç‰Œ
                        showdown_cards = ('7c', '8d')
                    
                    agent.record_hand_result(hand_id, opp_id, final_action, pot_outcome, showdown_cards)
                else:
                    # éshowdownç»“æŸ
                    final_action = np.random.choice(['fold', 'call'])
                    pot_outcome = -10.0 if final_action == 'fold' else 0.0
                    agent.record_hand_result(hand_id, opp_id, final_action, pot_outcome)


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("Pokeråœºæ™¯è¯„ä¼°ï¼ˆåŒ…å«Baselineå¯¹æ¯”ï¼‰")
    print("="*80)
    
    if not PokerRLAgent:
        print("\nâš ï¸ è­¦å‘Š: Poker Agentæ¨¡å—æœªæ‰¾åˆ°")
        print("è¯·ç¡®ä¿ memory/poker_agent.py å­˜åœ¨")
        return
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = PokerEvaluator()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    ground_truth = create_poker_ground_truth()
    test_episodes = create_poker_test_episodes()
    
    # åˆ›å»ºæˆ‘ä»¬çš„Poker Agent
    def create_our_agent():
        """åˆ›å»ºä½¿ç”¨æˆ‘ä»¬Memoryç³»ç»Ÿçš„Poker Agent"""
        from main import CognitiveAgent
        agent = CognitiveAgent(mode="langgraph")
        # å¦‚æœæœ‰PokerRLAgentï¼Œå¯ä»¥åŒ…è£…å®ƒ
        if PokerRLAgent:
            poker_agent = PokerRLAgent()
            poker_agent.memory_engine = agent.memory_engine
            return poker_agent
        return agent
    
    # å®šä¹‰æŒ‡æ ‡è®¡ç®—å‡½æ•°
    def calculate_metrics(agent, results):
        """è®¡ç®—Pokeråœºæ™¯çš„æŒ‡æ ‡"""
        # å¦‚æœæ˜¯æˆ‘ä»¬çš„PokerRLAgentï¼Œè¿è¡Œå®é™…è¯„ä¼°
        if PokerRLAgent and isinstance(agent, PokerRLAgent):
            try:
                # å¦‚æœè¿˜æ²¡æœ‰æ¨¡æ‹Ÿæ¸¸æˆï¼Œå…ˆæ¨¡æ‹Ÿ
                if hasattr(agent, 'opponent_memory'):
                    memory_stats = agent.opponent_memory.get_statistics()
                    if memory_stats.get('total_hands_tracked', 0) == 0:
                        simulate_poker_hands(agent, ground_truth, num_hands_per_opponent=30)
                
                # è¿è¡Œè¯„ä¼°
                eval_results = evaluator.comprehensive_evaluation(
                    agent, ground_truth, None, test_episodes
                )
                # ä»è¯„ä¼°ç»“æœä¸­æå–æŒ‡æ ‡
                metrics_dict = eval_results.get('metrics', {})
                return {
                    'hidden_state_prediction': metrics_dict.get('hidden_state_prediction_accuracy', 0.0),
                    'win_rate_improvement': metrics_dict.get('win_rate_improvement', 0.0),
                    'behavior_consistency': metrics_dict.get('behavior_consistency', 0.0)
                }
            except Exception as e:
                print(f"      âš ï¸ è¯„ä¼°å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # å¦‚æœæ˜¯baseline memoryï¼Œè¿”å›æ¨¡æ‹ŸæŒ‡æ ‡
        if hasattr(agent, 'store') and hasattr(agent, 'retrieve'):
            retrieved_count = results.get('retrieved_count', 0) if results else 0
            return {
                'hidden_state_prediction': min(0.5, retrieved_count / 10.0),
                'win_rate_improvement': min(0.1, retrieved_count / 20.0),
                'behavior_consistency': min(0.6, retrieved_count / 10.0)
            }
        
        # é»˜è®¤è¿”å›
        return {
            'hidden_state_prediction': 0.0,
            'win_rate_improvement': 0.0,
            'behavior_consistency': 0.0
        }
    
    # è¿è¡Œåœºæ™¯è¯„ä¼°
    if PokerRLAgent:
        try:
            our_agent = create_our_agent()
            
            # åœ¨è¯„ä¼°å‰æ¨¡æ‹Ÿæ¸¸æˆæ‰‹æ•°ï¼Œè®©agentå­¦ä¹ å¯¹æ‰‹
            print("\n1. æ¨¡æ‹Ÿæ¸¸æˆæ‰‹æ•°ï¼Œè®°å½•å¯¹æ‰‹åŠ¨ä½œ...")
            simulate_poker_hands(our_agent, ground_truth, num_hands_per_opponent=30)
            print(f"   å·²æ¨¡æ‹Ÿ {len(ground_truth)} ä¸ªå¯¹æ‰‹ï¼Œæ¯ä¸ª {30} æ‰‹")
            
            # æ‰“å°å­¦ä¹ åˆ°çš„å¯¹æ‰‹ä¿¡æ¯
            if hasattr(our_agent, 'get_system_statistics'):
                stats = our_agent.get_system_statistics()
                memory_stats = stats.get('memory', {})
                print(f"   è¿½è¸ªæ‰‹æ•°: {memory_stats.get('total_hands_tracked', 0)}")
                print(f"   å¯¹æ‰‹æ•°é‡: {memory_stats.get('total_opponents', 0)}")
            
            print("\n2. è¿è¡Œè¯„ä¼°...")
            results = evaluator.comprehensive_evaluation(
                our_agent, ground_truth, None, test_episodes
            )
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            evaluator.save_results(f'evaluation_results/poker_evaluation_{timestamp}.json')
            print("\nâœ“ Pokeråœºæ™¯è¯„ä¼°å®Œæˆ")
        except Exception as e:
            print(f"\nâš ï¸ è¯„ä¼°è¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            results = {}
    else:
        results = {}
    
    # è¿è¡ŒBaselineå¯¹æ¯”
    print("\n" + "="*80)
    print("å¼€å§‹Baselineå¯¹æ¯”...")
    print("="*80)
    
    comparison = ScenarioComparison("Poker")
    baseline_agents = create_baseline_agents("poker")
    
    # åˆ›å»ºæµ‹è¯•åœºæ™¯
    test_scenario = {
        'ground_truth': ground_truth,
        'test_episodes': test_episodes,
        'num_hands': 100
    }
    
    # è¿è¡Œå¯¹æ¯”
    comparison_results = comparison.compare_with_baselines(
        create_our_agent,
        baseline_agents,
        test_scenario,
        calculate_metrics
    )
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    comparison.save_results(f'evaluation_results/poker_comparison_{timestamp}.json')
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*80)
    print("å¯¹æ¯”æ€»ç»“")
    print("="*80)
    summary = comparison_results.get('summary', {})
    print(f"\næˆåŠŸå¯¹æ¯”çš„Baselineæ•°é‡: {summary.get('successful_baselines', 0)}/{summary.get('total_baselines', 0)}")
    if 'average_improvements' in summary:
        print("\nå¹³å‡æ”¹è¿›:")
        for metric, improvement in summary['average_improvements'].items():
            print(f"  {metric}: {improvement:+.4f}")


if __name__ == "__main__":
    main()

